{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e1edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76eb46f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full,X_test,y_train_full,y_test = train_test_split(housing.data,housing.target)\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X_train_full,y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13fb1a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7376 - val_loss: 0.5467\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5001 - val_loss: 0.4938\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4706 - val_loss: 0.4675\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4584 - val_loss: 0.4563\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4444 - val_loss: 0.4449\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.4345 - val_loss: 0.4352\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4278 - val_loss: 0.4267\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4192 - val_loss: 0.4238\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.4335\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 0.4150\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4083 - val_loss: 0.4095\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.4118\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.4053\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3980 - val_loss: 0.4025\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4006\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.3997\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3972 - val_loss: 0.3931\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.3937\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.3896\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3929\n",
      "162/162 [==============================] - 0s 701us/step - loss: 0.3855\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential([keras.layers.Dense(30,activation=\"relu\",input_shape=X_train.shape[1:]),keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",optimizer=\"sgd\")\n",
    "history = model.fit(X_train,y_train,epochs=20,validation_data=(X_valid,y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test,y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c03ceb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30,activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30,activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_,hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3cb5ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 30)           270         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 30)           930         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f9cebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5138 - val_loss: 0.5141\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5013 - val_loss: 0.5125\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4987 - val_loss: 0.5142\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4974 - val_loss: 0.5128\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4969 - val_loss: 0.5123\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4962 - val_loss: 0.5087\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.4957 - val_loss: 0.5076\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4959 - val_loss: 0.5072\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4957 - val_loss: 0.5083\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4953 - val_loss: 0.5131\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4957 - val_loss: 0.5076\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4939 - val_loss: 0.5090\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.4938 - val_loss: 0.5099\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4932 - val_loss: 0.5079\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 889us/step - loss: 0.4928 - val_loss: 0.5011\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4914 - val_loss: 0.5104\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4930 - val_loss: 0.5010\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4914 - val_loss: 0.4982\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4916 - val_loss: 0.5048\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4908 - val_loss: 0.5041\n",
      "162/162 [==============================] - 0s 666us/step - loss: 0.4947\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c397881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.3031 - val_loss: 1.0914\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.9016 - val_loss: 0.8465\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7747 - val_loss: 0.7721\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7199 - val_loss: 0.7259\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6815 - val_loss: 0.6894\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6504 - val_loss: 0.6598\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6245 - val_loss: 0.6338\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6026 - val_loss: 0.6117\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5840 - val_loss: 0.5928\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5678 - val_loss: 0.5762\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5532 - val_loss: 0.5613\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5409 - val_loss: 0.5484\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5297 - val_loss: 0.5377\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5198 - val_loss: 0.5287\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5120 - val_loss: 0.5196\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5046 - val_loss: 0.5121\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4980 - val_loss: 0.5062\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4925 - val_loss: 0.5010\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4885 - val_loss: 0.4970\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4843 - val_loss: 0.4927\n",
      "162/162 [==============================] - 0s 748us/step - loss: 0.4708\n"
     ]
    }
   ],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f51719f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.8926 - output_1_loss: 2.6514 - output_2_loss: 5.0632 - val_loss: 1.4331 - val_output_1_loss: 1.1323 - val_output_2_loss: 4.1411\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1384 - output_1_loss: 0.9009 - output_2_loss: 3.2758 - val_loss: 0.9766 - val_output_1_loss: 0.7949 - val_output_2_loss: 2.6126\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8635 - output_1_loss: 0.7180 - output_2_loss: 2.1730 - val_loss: 0.8103 - val_output_1_loss: 0.6935 - val_output_2_loss: 1.8612\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7504 - output_1_loss: 0.6477 - output_2_loss: 1.6754 - val_loss: 0.7318 - val_output_1_loss: 0.6417 - val_output_2_loss: 1.5422\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6936 - output_1_loss: 0.6080 - output_2_loss: 1.4641 - val_loss: 0.6881 - val_output_1_loss: 0.6085 - val_output_2_loss: 1.4046\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6598 - output_1_loss: 0.5814 - output_2_loss: 1.3652 - val_loss: 0.6600 - val_output_1_loss: 0.5845 - val_output_2_loss: 1.3394\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6359 - output_1_loss: 0.5608 - output_2_loss: 1.3116 - val_loss: 0.6389 - val_output_1_loss: 0.5657 - val_output_2_loss: 1.2973\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.6185 - output_1_loss: 0.5458 - output_2_loss: 1.2721 - val_loss: 0.6220 - val_output_1_loss: 0.5503 - val_output_2_loss: 1.2671\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6041 - output_1_loss: 0.5334 - output_2_loss: 1.2402 - val_loss: 0.6090 - val_output_1_loss: 0.5389 - val_output_2_loss: 1.2404\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5922 - output_1_loss: 0.5233 - output_2_loss: 1.2115 - val_loss: 0.5979 - val_output_1_loss: 0.5292 - val_output_2_loss: 1.2162\n",
      "162/162 [==============================] - 0s 786us/step - loss: 0.5738 - output_1_loss: 0.5079 - output_2_loss: 1.1664\n"
     ]
    }
   ],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")\n",
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bb0813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.9639 - val_loss: 1.0272\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8667 - val_loss: 0.8143\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7304 - val_loss: 0.7224\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6654 - val_loss: 0.6681\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6242 - val_loss: 0.6293\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5931 - val_loss: 0.5986\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5677 - val_loss: 0.5742\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5470 - val_loss: 0.5534\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5298 - val_loss: 0.5364\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1000us/step - loss: 0.5155 - val_loss: 0.5235\n",
      "162/162 [==============================] - 0s 664us/step - loss: 0.4926\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48c17776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022434C90EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.538143 ],\n",
       "       [1.7983489],\n",
       "       [1.8867365]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(\"moj_model_keras.h5\")\n",
    "model = keras.models.load_model(\"moj_model_keras.h5\")\n",
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d6cb9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x22430f03f70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights(\"my_keras_weights.ckpt\")\n",
    "model.load_weights(\"my_keras_weights.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d44069e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.8972 - val_loss: 0.7882\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6993 - val_loss: 0.6566\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6157 - val_loss: 0.6145\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5804 - val_loss: 0.5841\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5546 - val_loss: 0.5599\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5342 - val_loss: 0.5414\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5265\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5062 - val_loss: 0.5144\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4960 - val_loss: 0.5046\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4878 - val_loss: 0.4959\n",
      "162/162 [==============================] - 0s 776us/step - loss: 0.4725\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67ac5ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4809 - val_loss: 0.4891\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4752 - val_loss: 0.4835\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4705 - val_loss: 0.4797\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4664 - val_loss: 0.4746\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4630 - val_loss: 0.4709\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4593 - val_loss: 0.4682\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4572 - val_loss: 0.4651\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4545 - val_loss: 0.4622\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4519 - val_loss: 0.4598\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4497 - val_loss: 0.4572\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4476 - val_loss: 0.4560\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4456 - val_loss: 0.4535\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4442 - val_loss: 0.4509\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4423 - val_loss: 0.4496\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4402 - val_loss: 0.4477\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4387 - val_loss: 0.4464\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4368 - val_loss: 0.4445\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4436\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4344 - val_loss: 0.4416\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.4408\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4314 - val_loss: 0.4388\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4299 - val_loss: 0.4374\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4282 - val_loss: 0.4366\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4278 - val_loss: 0.4347\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4259 - val_loss: 0.4336\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.4318\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4322\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4223 - val_loss: 0.4303\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4215 - val_loss: 0.4286\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4202 - val_loss: 0.4275\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4183 - val_loss: 0.4271\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.4260\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4169 - val_loss: 0.4244\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 905us/step - loss: 0.4158 - val_loss: 0.4233\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.4143 - val_loss: 0.4258\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4137 - val_loss: 0.4206\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4128 - val_loss: 0.4200\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4117 - val_loss: 0.4189\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.4179\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4099 - val_loss: 0.4175\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4087 - val_loss: 0.4161\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4076 - val_loss: 0.4149\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.4145\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4058 - val_loss: 0.4131\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.4122\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4041 - val_loss: 0.4115\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.4102\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.4088\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.4078\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.4080\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3988 - val_loss: 0.4067\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3980 - val_loss: 0.4053\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 941us/step - loss: 0.3972 - val_loss: 0.4049\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.4032\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.4021\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3947 - val_loss: 0.4024\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3937 - val_loss: 0.4010\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.3928 - val_loss: 0.4011\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.3995\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3909 - val_loss: 0.3980\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.3972\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3891 - val_loss: 0.3960\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.3954\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.3949\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.3950\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3862 - val_loss: 0.3927\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.3922\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3923\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.3905\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3914\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3902\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.3891\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3814 - val_loss: 0.3882\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.3874\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.3864\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.3859\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.3846\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3779 - val_loss: 0.3858\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.3833\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.3820\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 0.3815\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.3811\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.3808\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.3802\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.3789\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3712 - val_loss: 0.3785\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3710 - val_loss: 0.3777\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.3775\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.3762\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3684 - val_loss: 0.3756\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 941us/step - loss: 0.3680 - val_loss: 0.3751\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 0.3747\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3673 - val_loss: 0.3742\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.3753\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3660 - val_loss: 0.3729\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3642 - val_loss: 0.3713\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.3715\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.3709\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.3704\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.3696\n",
      "162/162 [==============================] - 0s 664us/step - loss: 0.3626\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20279308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316/363 [=========================>....] - ETA: 0s - loss: 0.3628\n",
      "val/train: 1.02\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3609 - val_loss: 0.3688\n"
     ]
    }
   ],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))\n",
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2bdf248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.8972 - val_loss: 0.7882\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6993 - val_loss: 0.6566\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6157 - val_loss: 0.6145\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5804 - val_loss: 0.5841\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5546 - val_loss: 0.5599\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5342 - val_loss: 0.5414\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5265\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5062 - val_loss: 0.5144\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4960 - val_loss: 0.5046\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.4878 - val_loss: 0.4959\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4809 - val_loss: 0.4898\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4751 - val_loss: 0.4835\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4708 - val_loss: 0.4783\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4666 - val_loss: 0.4746\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4627 - val_loss: 0.4708\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4597 - val_loss: 0.4678\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4566 - val_loss: 0.4645\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4544 - val_loss: 0.4627\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4522 - val_loss: 0.4595\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4497 - val_loss: 0.4579\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4478 - val_loss: 0.4552\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4459 - val_loss: 0.4532\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4437 - val_loss: 0.4519\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4426 - val_loss: 0.4495\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4404 - val_loss: 0.4482\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4383 - val_loss: 0.4458\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4370 - val_loss: 0.4455\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4354 - val_loss: 0.4435\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 968us/step - loss: 0.4343 - val_loss: 0.4417\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.4403\n"
     ]
    }
   ],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir\n",
    "'./my_logs/run_2021_02_13-18_39_20'\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6369c88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c9686b44610f6b49\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c9686b44610f6b49\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f1177f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6250 - val_loss: 0.5520\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4598 - val_loss: 0.4195\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4088 - val_loss: 0.3970\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.3608\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3767 - val_loss: 0.3632\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.4118\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 0.3482\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3517\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3388 - val_loss: 0.3536\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3335 - val_loss: 0.3520\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.3583\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3284 - val_loss: 0.3758\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3223 - val_loss: 0.3839\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3220 - val_loss: 0.3522\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3158 - val_loss: 0.3193\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3160 - val_loss: 0.3232\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3083 - val_loss: 0.3182\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.3443\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3084 - val_loss: 0.3396\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3069 - val_loss: 0.3340\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3032 - val_loss: 0.3220\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2985 - val_loss: 0.3232\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2985 - val_loss: 0.3140\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2986 - val_loss: 0.3261\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.3213\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2965 - val_loss: 0.3304\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 949us/step - loss: 0.2964 - val_loss: 0.3234\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3012 - val_loss: 0.3252\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2922 - val_loss: 0.3120\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2918 - val_loss: 0.3023\n"
     ]
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2\n",
    "'./my_logs/run_2021_02_13-18_39_31'\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=0.05))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81347b40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
